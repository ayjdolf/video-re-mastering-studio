import streamlit as st
import streamlit.components.v1 as components
import time
import os
import pandas as pd
import whisper
import cv2
import numpy as np
import zipfile
import io
import sys
import subprocess
from moviepy.editor import VideoFileClip

# --- [íŠ¹ë‹¨ì˜ ì¡°ì¹˜] ë¼ì´ë¸ŒëŸ¬ë¦¬ ìë™ ì„¤ì¹˜ & ì—…ë°ì´íŠ¸ ---
# í”„ë¡œê·¸ë¨ ì‹œì‘ ì‹œ ìë™ìœ¼ë¡œ ìµœì‹  ë²„ì „ì„ ì„¤ì¹˜í•©ë‹ˆë‹¤.
try:
    import google.generativeai as genai
    # ë²„ì „ì´ ë„ˆë¬´ ë‚®ìœ¼ë©´ 404 ì—ëŸ¬ê°€ ë‚˜ë¯€ë¡œ ê°•ì œ ì—…ë°ì´íŠ¸ ì‹œë„
    subprocess.check_call([sys.executable, "-m", "pip", "install", "-U", "google-generativeai"])
    import google.generativeai as genai
except ImportError:
    st.warning("âš ï¸ AI ë¶€í’ˆì´ ì—†ì–´ì„œ ì„¤ì¹˜ ì¤‘ì…ë‹ˆë‹¤... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”!")
    subprocess.check_call([sys.executable, "-m", "pip", "install", "-U", "google-generativeai"])
    import google.generativeai as genai
    st.success("âœ… ì„¤ì¹˜ ì™„ë£Œ! ìë™ìœ¼ë¡œ ë‹¤ì‹œ ì‹œì‘ë©ë‹ˆë‹¤.")
    time.sleep(1)
    st.rerun()

# --- ê¸°ë³¸ ì„¤ì • ---
st.set_page_config(page_title="AI ì˜ìƒ ë¦¬ë§ˆìŠ¤í„°ë§ ìŠ¤íŠœë””ì˜¤", layout="wide")

if not os.path.exists("extracted_slides"):
    os.makedirs("extracted_slides")

# --- ì„¸ì…˜ ìƒíƒœ ---
if 'script_df' not in st.session_state:
    st.session_state.script_df = None
if 'slides_data' not in st.session_state:
    st.session_state.slides_data = None
if 'storyboard_df' not in st.session_state:
    st.session_state.storyboard_df = None

# --- ìŠ¤í¬ë¡¤ í•¨ìˆ˜ ---
def scroll_to_bottom():
    js = """
    <script>
        var body = window.parent.document.body;
        setTimeout(function() {
            window.parent.scrollTo(0, body.scrollHeight);
        }, 500);
    </script>
    """
    components.html(js, height=0)

# --- ê¸°ëŠ¥ í•¨ìˆ˜ë“¤ ---
def extract_audio(video_path):
    audio_path = "temp_audio.mp3"
    try:
        video = VideoFileClip(video_path)
        video.audio.write_audiofile(audio_path, codec='mp3', logger=None)
        return audio_path
    except Exception as e:
        return None

@st.cache_resource
def load_whisper_model():
    return whisper.load_model("base") 

def analyze_audio(audio_path, model):
    result = model.transcribe(audio_path)
    return result['segments']

def analyze_scenes(video_path, cut_x_ratio, cut_y_ratio, sensitivity, min_interval):
    cap = cv2.VideoCapture(video_path)
    fps = cap.get(cv2.CAP_PROP_FPS)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    saved_slides = []
    last_saved_frame = None 
    last_saved_time = -999 
    
    interval = int(fps) 
    progress_bar = st.progress(0)
    
    for i, frame_idx in enumerate(range(0, total_frames, interval)):
        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
        ret, frame = cap.read()
        if not ret:
            break
            
        if i % 10 == 0:
            progress_bar.progress(frame_idx / total_frames)
            
        current_time = frame_idx / fps

        if (current_time - last_saved_time) < min_interval:
            continue

        h, w, _ = frame.shape
        
        # Masking
        analyze_frame = frame.copy()
        x_start = int(w * cut_x_ratio)
        y_start = int(h * cut_y_ratio)
        analyze_frame[y_start:h, x_start:w] = 0
        
        # Change Detection
        gray = cv2.cvtColor(analyze_frame, cv2.COLOR_BGR2GRAY)
        gray = cv2.GaussianBlur(gray, (5, 5), 0)
        
        is_new_slide = False
        
        if last_saved_frame is None:
            is_new_slide = True 
        else:
            score = cv2.absdiff(last_saved_frame, gray)
            score_mean = np.mean(score)
            
            if score_mean > sensitivity: 
                is_new_slide = True
        
        if is_new_slide:
            filename = f"extracted_slides/slide_{int(current_time)}.jpg"
            
            debug_frame = frame.copy()
            cv2.rectangle(debug_frame, (0, 0), (w, h), (0, 255, 0), 2)
            cv2.rectangle(debug_frame, (x_start, y_start), (w, h), (0, 0, 255), -1)
            cv2.putText(debug_frame, "IGNORED", (x_start + 10, y_start + 30), 
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
            
            cv2.imwrite(filename, debug_frame) 
            
            saved_slides.append({
                "ì‹œê°„": time.strftime('%H:%M:%S', time.gmtime(current_time)),
                "ì´ˆ": current_time,
                "íŒŒì¼ëª…": filename
            })
            
            last_saved_frame = gray 
            last_saved_time = current_time 
            
    cap.release()
    progress_bar.empty()
    return saved_slides

def create_slide_based_storyboard(script_df, slides):
    df_slides = pd.DataFrame(slides)
    df_slides = df_slides.sort_values(by="ì´ˆ")
    
    storyboard_data = []
    
    for i in range(len(df_slides)):
        current_slide = df_slides.iloc[i]
        start_time = current_slide['ì´ˆ']
        
        if i < len(df_slides) - 1:
            end_time = df_slides.iloc[i+1]['ì´ˆ']
        else:
            end_time = 999999 
            
        mask = (script_df['ì‹œì‘_ì´ˆ'] >= start_time) & (script_df['ì‹œì‘_ì´ˆ'] < end_time)
        matched_scripts = script_df[mask]
        
        full_text = " ".join(matched_scripts['ë‚´ìš©'].tolist())
        
        storyboard_data.append({
            "No": i + 1, 
            "Time": f"{current_slide['ì‹œê°„']} ~ {time.strftime('%H:%M:%S', time.gmtime(end_time)) if end_time != 999999 else 'End'}",
            "Script": full_text,
            "Image": current_slide['íŒŒì¼ëª…'],
            "AI_Description": "" 
        })
        
    return pd.DataFrame(storyboard_data)

def analyze_image_with_gemini(image_path, api_key):
    try:
        genai.configure(api_key=api_key)
        # ë§Œì•½ ì´ê²ƒë„ ì•ˆ ë˜ë©´ 'gemini-1.5-pro' ë¡œ ë³€ê²½ ê°€ëŠ¥
        model = genai.GenerativeModel('gemini-1.5-flash') 
        
        img = cv2.imread(image_path)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        from PIL import Image
        pil_img = Image.fromarray(img)
        
        prompt = """
        ì´ ì´ë¯¸ì§€ëŠ” êµìœ¡ ì˜ìƒì˜ í•œ ì¥ë©´(PPT ìŠ¬ë¼ì´ë“œ)ì´ì•¼. 
        ì´ ìŠ¬ë¼ì´ë“œë¥¼ ë‚˜ì¤‘ì— AI ì´ë¯¸ì§€ ìƒì„±ê¸°ë¡œ ë‹¤ì‹œ ê·¸ë¦´ ìˆ˜ ìˆë„ë¡ ìì„¸íˆ ë¬˜ì‚¬í•´ì¤˜.
        ë‹¤ìŒ ë‚´ìš©ì„ í¬í•¨í•´ì„œ í•œê¸€ë¡œ 3ë¬¸ì¥ ì´ë‚´ë¡œ ìš”ì•½í•´:
        1. ì‹œê°ì  ìš”ì†Œ (ë°°ê²½ ìŠ¤íƒ€ì¼, ê·¸ë¦¼, ë ˆì´ì•„ì›ƒ)
        2. ì£¼ìš” í…ìŠ¤íŠ¸ ë‚´ìš©ì´ë‚˜ ì¸ìš©êµ¬ (OCR)
        3. ì „ì²´ì ì¸ ë¶„ìœ„ê¸°ë‚˜ ìƒí™©
        """
        
        response = model.generate_content([prompt, pil_img])
        return response.text
    except Exception as e:
        # ì—ëŸ¬ ë©”ì‹œì§€ë¥¼ ì¢€ ë” ìì„¸íˆ ì¶œë ¥
        return f"ë¶„ì„ ì‹¤íŒ¨: {str(e)}"

def create_zip_file(folder_path):
    zip_buffer = io.BytesIO()
    with zipfile.ZipFile(zip_buffer, "a", zipfile.ZIP_DEFLATED, False) as zip_file:
        for root, dirs, files in os.walk(folder_path):
            for file in files:
                file_path = os.path.join(root, file)
                zip_file.write(file_path, arcname=file)
    return zip_buffer.getvalue()

# --- ë©”ì¸ UI ---
st.title("ğŸ¥ AI Video Re-Mastering Studio")

with st.sidebar:
    st.header("1. íŒŒì¼ ì…ë ¥")
    video_source = st.file_uploader("ê°•ì˜ ì˜ìƒ ì—…ë¡œë“œ", type=['mp4', 'avi', 'mov'])
    
    st.divider()
    st.header("âš™ï¸ ì„¤ì • (Settings)")
    gemini_api_key = st.text_input("ğŸ’ Gemini API Key (ì„ íƒ)", type="password", help="í‚¤ë¥¼ ì…ë ¥í•˜ë©´ AIê°€ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•´ì¤ë‹ˆë‹¤.")
    
    st.divider()
    st.subheader("ì •ë°€ ë¶„ì„ ì„¤ì •")
    cut_x_input = st.slider("ê°€ë¡œ ìœ„ì¹˜", 0.5, 0.95, 0.75, 0.05)
    cut_y_input = st.slider("ì„¸ë¡œ ìœ„ì¹˜", 0.3, 0.9, 0.6, 0.05)
    sensitivity_input = st.slider("ë¯¼ê°ë„", 1.0, 20.0, 5.0)
    min_interval_input = st.slider("ì¿¨íƒ€ì„", 1, 60, 5)

if video_source:
    with open("temp_video.mp4", "wb") as f:
        f.write(video_source.read())
    
    st.info("âœ… ì˜ìƒ ì¤€ë¹„ ì™„ë£Œ!")
    
    tab1, tab2 = st.tabs(["ğŸ” 1ë‹¨ê³„: ì¬ë£Œ ì¶”ì¶œ", "ğŸ“ 2ë‹¨ê³„: ìŠ¤í† ë¦¬ë³´ë“œ"])
    
    # --- [íƒ­ 1] ---
    with tab1:
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸš€ (1) ìŒì„± ëŒ€ë³¸ ì¶”ì¶œ", use_container_width=True):
                model = load_whisper_model()
                audio_file = extract_audio("temp_video.mp4")
                if audio_file:
                    with st.spinner("ë“£ëŠ” ì¤‘..."):
                        segments = analyze_audio(audio_file, model)
                        data = [{"ì‹œì‘": time.strftime('%H:%M:%S', time.gmtime(s['start'])),
                                 "ì‹œì‘_ì´ˆ": s['start'], "ë‚´ìš©": s['text']} for s in segments]
                        st.session_state.script_df = pd.DataFrame(data)
                        st.success("ì™„ë£Œ!")
                        scroll_to_bottom() 
            if st.session_state.script_df is not None:
                st.dataframe(st.session_state.script_df, height=300)

        with col2:
            if st.button("ğŸ¨ (2) PPT ì¥ë©´ ì¶”ì¶œ", use_container_width=True):
                with st.spinner("ë³´ëŠ” ì¤‘..."):
                    slides = analyze_scenes("temp_video.mp4", cut_x_input, cut_y_input, sensitivity_input, min_interval_input)
                    if slides:
                        st.session_state.slides_data = slides
                        st.success(f"{len(slides)}ì¥ ì¶”ì¶œ ì™„ë£Œ!")
                        scroll_to_bottom() 
            
            if st.session_state.slides_data is not None:
                st.write(f"ì´ {len(st.session_state.slides_data)}ì¥ì˜ PPT í™•ë³´")
                
                zip_data = create_zip_file("extracted_slides")
                st.download_button("ğŸ“¦ ëª¨ë“  ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ (.ZIP)", zip_data, "ppt_slides.zip", "application/zip", type="primary")
                
                with st.expander("ğŸ“¸ ì „ì²´ ì¥ë©´ í¼ì³ë³´ê¸°"):
                    cols = st.columns(3)
                    for idx, slide in enumerate(st.session_state.slides_data):
                        with cols[idx % 3]:
                            st.image(slide['íŒŒì¼ëª…'], caption=f"Scene #{idx+1} [{slide['ì‹œê°„']}]", use_container_width=True)

    # --- [íƒ­ 2] ---
    with tab2:
        st.subheader("ğŸ“ ì¥ë©´(Scene) ë¦¬ìŠ¤íŠ¸ & AI ë¶„ì„")
        
        if st.session_state.script_df is None or st.session_state.slides_data is None:
            st.warning("âš ï¸ 1ë‹¨ê³„ì—ì„œ ìŒì„±ê³¼ ì´ë¯¸ì§€ë¥¼ ëª¨ë‘ ì¶”ì¶œí•´ì£¼ì„¸ìš”.")
        else:
            if st.session_state.storyboard_df is None:
                st.session_state.storyboard_df = create_slide_based_storyboard(st.session_state.script_df, st.session_state.slides_data)
            
            c1, c2 = st.columns([1, 1])
            with c1:
                if gemini_api_key:
                    if st.button("ğŸ¤– AI ì¥ë©´ ì •ë°€ ë¶„ì„ ì‹œì‘ (Gemini)", type="primary"):
                        progress_bar = st.progress(0)
                        total = len(st.session_state.storyboard_df)
                        for index, row in st.session_state.storyboard_df.iterrows():
                            if not row['AI_Description']:
                                desc = analyze_image_with_gemini(row['Image'], gemini_api_key)
                                st.session_state.storyboard_df.at[index, 'AI_Description'] = desc
                            progress_bar.progress((index + 1) / total)
                        
                        st.success("ë¶„ì„ ì™„ë£Œ!")
                        scroll_to_bottom() 
                        st.rerun()
                else:
                    st.info("ğŸ’¡ ì‚¬ì´ë“œë°”ì— Gemini API í‚¤ë¥¼ ë„£ìœ¼ë©´ ì´ë¯¸ì§€ ë¶„ì„ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.")

            with c2:
                csv_sb = st.session_state.storyboard_df.to_csv(index=False).encode('utf-8-sig')
                st.download_button("ğŸ’¾ ì „ì²´ ë¦¬ìŠ¤íŠ¸ ë‹¤ìš´ë¡œë“œ (Excel)", csv_sb, 'storyboard_final.csv', 'text/csv', type="primary")
            
            st.divider()
            
            # [5ë‹¨ ë¦¬ìŠ¤íŠ¸ ì¶œë ¥] 
            for index, row in st.session_state.storyboard_df.iterrows():
                cols = st.columns([0.4, 0.8, 2.5, 1.5, 1.5])
                
                with cols[0]:
                    st.markdown(f"**#{row['No']}**")
                
                with cols[1]:
                    st.caption(row['Time'])
                
                with cols[2]:
                    st.text_area(f"s_{index}", row['Script'], height=120, label_visibility="collapsed")
                    
                with cols[3]:
                    st.image(row['Image'], use_container_width=True)
                    
                with cols[4]:
                    if row['AI_Description']:
                        if "ë¶„ì„ ì‹¤íŒ¨" in row['AI_Description']:
                             st.error("Error: í‚¤ í™•ì¸ í•„ìš”")
                             with st.expander("ì—ëŸ¬ ë‚´ìš© ë³´ê¸°"):
                                 st.write(row['AI_Description'])
                        else:
                            st.info(row['AI_Description'])
                    else:
                        st.caption("Waiting...")
                
                st.markdown("---")