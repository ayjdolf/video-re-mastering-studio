import streamlit as st
import cv2
import os
import shutil
import numpy as np
import pandas as pd
import google.generativeai as genai
from moviepy.editor import VideoFileClip

# ==========================================
# 1. í™˜ê²½ ì„¤ì •
# ==========================================
BASE_DIR = os.getcwd()
TEMP_DIR = os.path.join(BASE_DIR, "temp_workspace")
OUTPUT_DIR = os.path.join(BASE_DIR, "extracted_scenes")
PPT_DIR = os.path.join(BASE_DIR, "uploaded_ppts")
AUDIO_PATH = os.path.join(TEMP_DIR, "audio.mp3")

# ==========================================
# 2. í•µì‹¬ ë¶„ì„ ì—”ì§„ (Track 1 & Track 2)
# ==========================================

# [Track 1] PPT ì›ë³¸ê³¼ ë¹„êµí•´ì„œ ì¥ë©´ ì°¾ê¸° (ë§¤ì¹­ ëª¨ë“œ)
def extract_scenes_by_matching(video_path, ppt_files, progress_bar):
    cap = cv2.VideoCapture(video_path)
    fps = cap.get(cv2.CAP_PROP_FPS)
    duration = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) / fps if fps > 0 else 0
    
    # PPT ì´ë¯¸ì§€ ë¯¸ë¦¬ ë¡œë“œ ë° ì „ì²˜ë¦¬
    ppt_imgs = []
    ppt_filenames = []
    
    # ì˜ìƒ í¬ê¸°ì— ë§ì¶° PPT ë¦¬ì‚¬ì´ì§•ì„ ìœ„í•´ ì²« í”„ë ˆì„ ì½ê¸°
    ret, first_frame = cap.read()
    if not ret: return []
    h_vid, w_vid = first_frame.shape[:2]
    
    # ì—…ë¡œë“œëœ PPT ì½ì–´ì„œ ë©”ëª¨ë¦¬ì— ì˜¬ë¦¬ê¸°
    sorted_ppts = sorted(ppt_files, key=lambda x: x.name) # ì´ë¦„ìˆœ ì •ë ¬
    for p_file in sorted_ppts:
        # íŒŒì¼ ì €ì¥ í›„ ì½ê¸°
        p_path = os.path.join(PPT_DIR, p_file.name)
        with open(p_path, "wb") as f: f.write(p_file.getbuffer())
        
        img = cv2.imread(p_path)
        if img is not None:
            # ì˜ìƒ í¬ê¸°ì™€ ë˜‘ê°™ì´ ë¦¬ì‚¬ì´ì§• (ë¹„êµë¥¼ ìœ„í•´)
            img_resized = cv2.resize(img, (w_vid, h_vid))
            gray_ppt = cv2.cvtColor(img_resized, cv2.COLOR_BGR2GRAY)
            ppt_imgs.append(gray_ppt)
            ppt_filenames.append(p_file.name)

    if not ppt_imgs: return []

    scene_data = []
    current_ppt_idx = 0
    last_match_time = -999
    
    status = st.empty()
    status.write(f"ğŸ§© PPT {len(ppt_imgs)}ì¥ê³¼ ì˜ìƒ ë§¤ì¹­ ì‹œì‘...")

    # ì˜ìƒ ìŠ¤ìº” (ì†ë„ë¥¼ ìœ„í•´ 0.5ì´ˆ ë‹¨ìœ„ë¡œ ê±´ë„ˆë›°ë©° ìŠ¤ìº”)
    step_frames = int(fps * 0.5) 
    
    while True:
        # í”„ë ˆì„ ê±´ë„ˆë›°ê¸°
        for _ in range(step_frames): cap.grab()
        ret, frame = cap.read()
        if not ret: break
        
        current_time = cap.get(cv2.CAP_PROP_POS_MSEC) / 1000.0
        if duration > 0: progress_bar.progress(min(int((current_time/duration)*40), 40))

        # í˜„ì¬ í”„ë ˆì„ í‘ë°± ë³€í™˜
        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

        # í˜„ì¬ ë³´ê³  ìˆëŠ” PPTì™€ ë‹¤ìŒ PPTë‘ ë¹„êµ
        # ë¡œì§: "í˜„ì¬ PPTë³´ë‹¤ ë‹¤ìŒ PPTë‘ ë” ë¹„ìŠ·í•´ì§€ë©´ ë„˜ì–´ê°„ ê±¸ë¡œ ê°„ì£¼"
        
        score_current = 0
        score_next = 0
        
        # í˜„ì¬ PPTì™€ ìœ ì‚¬ë„ (êµ¬ì¡°ì  ìœ ì‚¬ë„ ëŒ€ì‹  ê°„ë‹¨íˆ í”½ì…€ ì°¨ì´ ì—­ìˆ˜ ì‚¬ìš©)
        diff_curr = np.mean(cv2.absdiff(frame_gray, ppt_imgs[current_ppt_idx]))
        score_current = 100 - diff_curr # ì°¨ì´ê°€ ì‘ì„ìˆ˜ë¡ ì ìˆ˜ ë†’ìŒ
        
        # ë‹¤ìŒ PPTê°€ ìˆë‹¤ë©´ ë¹„êµ
        if current_ppt_idx < len(ppt_imgs) - 1:
            diff_next = np.mean(cv2.absdiff(frame_gray, ppt_imgs[current_ppt_idx+1]))
            score_next = 100 - diff_next
            
            # ë‹¤ìŒ PPTë‘ í›¨ì”¬ ë” ë¹„ìŠ·í•´ì§€ë©´ ì¸ë±ìŠ¤ ë³€ê²½ (ì¥ë©´ ì „í™˜)
            # 10ì  ì´ìƒ ì°¨ì´ë‚˜ë©´ í™•ì‹¤í•˜ê²Œ ë„˜ì–´ê°„ ê²ƒ
            if score_next > score_current + 10: 
                current_ppt_idx += 1
                
                # ê²°ê³¼ ì €ì¥
                save_name = f"match_scene_{current_ppt_idx+1:02d}.jpg"
                save_path = os.path.join(OUTPUT_DIR, save_name)
                cv2.imwrite(save_path, frame) # ì˜ìƒ í”„ë ˆì„ ì €ì¥
                
                # í˜¹ì€ ì›ë³¸ PPTë¥¼ ê²°ê³¼ë¡œ ì“°ê³  ì‹¶ë‹¤ë©´ ì•„ë˜ ì£¼ì„ í•´ì œ
                # cv2.imwrite(save_path, cv2.imread(os.path.join(PPT_DIR, ppt_filenames[current_ppt_idx])))

                scene_data.append({
                    "seq": current_ppt_idx + 1,
                    "time": current_time,
                    "path": save_path,
                    "filename": save_name,
                    "ppt_source": ppt_filenames[current_ppt_idx]
                })
                status.write(f"âœ… PPT {current_ppt_idx+1}ë²ˆ ë§¤ì¹­ ì„±ê³µ! ({current_time:.1f}ì´ˆ)")

    cap.release()
    status.empty()
    
    # ì²« ì¥ë©´(PPT 1ë²ˆ)ì´ ëˆ„ë½ë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ê°•ì œ ì¶”ê°€ (0ì´ˆ)
    if not scene_data:
        first_save = os.path.join(OUTPUT_DIR, "match_scene_01.jpg")
        cv2.imwrite(first_save, first_frame)
        scene_data.append({"seq": 1, "time": 0.0, "path": first_save, "filename": "match_scene_01.jpg"})
        
    return scene_data


# [Track 2] ìë™ ê°ì§€ ëª¨ë“œ (ê¸°ì¡´ ë¡œì§)
def extract_scenes_auto(video_path, sensitivity, cooldown, mask_dir, w_ratio, h_ratio, progress_bar):
    cap = cv2.VideoCapture(video_path)
    fps = cap.get(cv2.CAP_PROP_FPS)
    duration = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) / fps if fps > 0 else 0
    
    prev_frame = None
    last_capture_time = -cooldown
    scene_data = [] 
    scene_count = 0
    status_text = st.empty()

    while True:
        ret, frame = cap.read()
        if not ret: break
        current_time = cap.get(cv2.CAP_PROP_POS_MSEC) / 1000.0
        
        if duration > 0 and int(current_time)%2==0:
            progress_bar.progress(min(int((current_time/duration)*40), 40))

        if current_time - last_capture_time < cooldown: continue

        h, w = frame.shape[:2]
        mask_w_px = int(w * (w_ratio / 100))
        mask_h_px = int(h * (h_ratio / 100))
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        analyze_area = gray.copy()

        if mask_dir == "ìš°ì¸¡ í•˜ë‹¨": analyze_area[h-mask_h_px:h, w-mask_w_px:w] = 0
        elif mask_dir == "ì¢Œì¸¡ í•˜ë‹¨": analyze_area[h-mask_h_px:h, 0:mask_w_px] = 0
        elif mask_dir == "ìš°ì¸¡ ìƒë‹¨": analyze_area[0:mask_h_px, w-mask_w_px:w] = 0

        is_changed = False
        if prev_frame is None: is_changed = True
        else:
            diff = np.mean(cv2.absdiff(prev_frame, analyze_area))
            if diff > sensitivity: is_changed = True

        if is_changed:
            scene_count += 1
            save_name = f"auto_scene_{scene_count:03d}.jpg"
            save_path = os.path.join(OUTPUT_DIR, save_name)
            cv2.imwrite(save_path, frame)
            scene_data.append({"seq": scene_count, "time": current_time, "path": save_path, "filename": save_name})
            last_capture_time = current_time
            prev_frame = analyze_area
            status_text.write(f"ğŸ“¸ ë³€í™” ê°ì§€: {scene_count}ë²ˆ ì¥ë©´")

    cap.release()
    status_text.empty()
    return scene_data

# ==========================================
# 3. ê³µí†µ ìœ í‹¸ë¦¬í‹° (ì´ˆê¸°í™”, Whisper, Gemini)
# ==========================================
def init_environment():
    try:
        for d in [TEMP_DIR, OUTPUT_DIR, PPT_DIR]:
            if os.path.exists(d): shutil.rmtree(d)
            os.makedirs(d, exist_ok=True)
    except: pass

def run_gemini(image_path, api_key):
    if not api_key: return "API í‚¤ ì—†ìŒ"
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel('gemini-1.5-flash')
        img = genai.upload_file(image_path)
        return model.generate_content(["ì´ í™”ë©´ ìš”ì•½", img]).text
    except Exception as e: return f"Gemini Error: {e}"

def run_whisper(video_path, api_key):
    if not api_key: return "API í‚¤ ì—†ìŒ"
    try:
        if os.path.exists(AUDIO_PATH): os.remove(AUDIO_PATH)
        clip = VideoFileClip(video_path)
        clip.audio.write_audiofile(AUDIO_PATH, logger=None)
        clip.close()
        
        from openai import OpenAI
        client = OpenAI(api_key=api_key)
        with open(AUDIO_PATH, "rb") as f:
            return client.audio.transcriptions.create(model="whisper-1", file=f, response_format="text")
    except Exception as e: return f"Whisper Error: {e}"

def draw_mask_preview(frame, direction, w_ratio, h_ratio):
    preview = frame.copy()
    h, w = preview.shape[:2]
    mask_w, mask_h = int(w*(w_ratio/100)), int(h*(h_ratio/100))
    if direction == "ìš°ì¸¡ í•˜ë‹¨": cv2.rectangle(preview, (w-mask_w, h-mask_h), (w, h), (0,0,255), -1)
    elif direction == "ì¢Œì¸¡ í•˜ë‹¨": cv2.rectangle(preview, (0, h-mask_h), (mask_w, h), (0,0,255), -1)
    elif direction == "ìš°ì¸¡ ìƒë‹¨": cv2.rectangle(preview, (w-mask_w, 0), (w, mask_h), (0,0,255), -1)
    return preview

# ==========================================
# 4. ë©”ì¸ UI
# ==========================================
st.set_page_config(page_title="í—Œìˆ˜í•™ë‹¹ ë¶„ì„ê¸° Final", layout="wide")
st.title("ğŸ¬ í—Œìˆ˜í•™ë‹¹ ì½˜í…ì¸  ë¶„ì„ê¸°")

with st.sidebar:
    st.header("ì„¤ì •")
    openai_key = st.text_input("OpenAI Key", type="password")
    google_key = st.text_input("Gemini Key", type="password")
    st.divider()
    
    st.subheader("ëª¨ë“œ ì„¤ì •")
    # ì—¬ê¸°ê°€ í•µì‹¬ì…ë‹ˆë‹¤! PPT ìœ ë¬´ì— ë”°ë¼ ì „ëµì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
    mode_info = st.empty()
    
    st.divider()
    st.subheader("ìë™ ê°ì§€ ì˜µì…˜ (PPT ì—†ì„ ë•Œë§Œ ì‚¬ìš©)")
    sensitivity = st.slider("ë¯¼ê°ë„", 5, 50, 15)
    cooldown = st.slider("ìµœì†Œ ê°„ê²©", 1.0, 5.0, 2.0)
    mask_dir = st.selectbox("ê°€ë¦´ ìœ„ì¹˜", ["ì—†ìŒ", "ìš°ì¸¡ í•˜ë‹¨", "ì¢Œì¸¡ í•˜ë‹¨", "ìš°ì¸¡ ìƒë‹¨"])
    mask_w, mask_h = st.slider("ê°€ë¡œ %", 0,50,20), st.slider("ì„¸ë¡œ %", 0,50,20)
    
    if st.button("ğŸ—‘ï¸ ì´ˆê¸°í™”"):
        st.experimental_rerun()

col1, col2 = st.columns(2)
with col1:
    uploaded_video = st.file_uploader("1. ì˜ìƒ íŒŒì¼", type=["mp4"])
    if uploaded_video:
        if not os.path.exists(TEMP_DIR): os.makedirs(TEMP_DIR)
        video_path = os.path.join(TEMP_DIR, "input.mp4")
        with open(video_path, "wb") as f: f.write(uploaded_video.getbuffer())
        
        cap = cv2.VideoCapture(video_path)
        ret, frame = cap.read()
        cap.release()
        if ret:
            prev_img = draw_mask_preview(frame, mask_dir, mask_w, mask_h)
            st.image(cv2.cvtColor(prev_img, cv2.COLOR_BGR2RGB), caption="ë¯¸ë¦¬ë³´ê¸°")

with col2:
    uploaded_ppts = st.file_uploader("2. PPT ì´ë¯¸ì§€ë“¤ (ë§¤ì¹­ìš©)", accept_multiple_files=True)
    if uploaded_ppts:
        st.success(f"âœ… PPT {len(uploaded_ppts)}ì¥ ë¡œë“œë¨! [Track 1: ë§¤ì¹­ ëª¨ë“œ]ë¡œ ì‘ë™í•©ë‹ˆë‹¤.")
        mode_info.success("ë§¤ì¹­ ëª¨ë“œ í™œì„±í™”ë¨")
    else:
        st.info("PPTê°€ ì—†ìŠµë‹ˆë‹¤. [Track 2: ìë™ ê°ì§€ ëª¨ë“œ]ë¡œ ì‘ë™í•©ë‹ˆë‹¤.")
        mode_info.info("ìë™ ê°ì§€ ëª¨ë“œ")

st.divider()

if uploaded_video and st.button("ğŸš€ ë¶„ì„ ì‹œì‘", type="primary"):
    init_environment()
    progress_bar = st.progress(0)
    video_path = os.path.join(TEMP_DIR, "input.mp4")
    # íŒŒì¼ ë‹¤ì‹œ í™•ë³´ (ì´ˆê¸°í™” ëŒ€ë¹„)
    with open(video_path, "wb") as f: f.write(uploaded_video.getbuffer())
    
    # === [ë¶„ê¸°ì ] PPTê°€ ìˆëƒ ì—†ëƒì— ë”°ë¼ ë‹¤ë¥¸ í•¨ìˆ˜ í˜¸ì¶œ ===
    if uploaded_ppts:
        st.write("ğŸ”„ **Track 1 ê°€ë™:** PPT ì´ë¯¸ì§€ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì˜ìƒì„ ë¶„ì„í•©ë‹ˆë‹¤...")
        scenes = extract_scenes_by_matching(video_path, uploaded_ppts, progress_bar)
    else:
        st.write("ğŸ¥ **Track 2 ê°€ë™:** í™”ë©´ ë³€í™”ë¥¼ ê°ì§€í•˜ì—¬ ì˜ìƒì„ ë¶„ì„í•©ë‹ˆë‹¤...")
        scenes = extract_scenes_auto(video_path, sensitivity, cooldown, mask_dir, mask_w, mask_h, progress_bar)
    
    if not scenes:
        st.error("ì¥ë©´ ì¶”ì¶œ ì‹¤íŒ¨. ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”.")
        st.stop()
        
    st.success(f"Step 1 ì™„ë£Œ: {len(scenes)}ê°œ ì¥ë©´")
    
    # Step 2: Gemini & Whisper (ê³µí†µ)
    st.info("AI ë¶„ì„ ì‹œì‘...")
    final_data = []
    for i, s in enumerate(scenes):
        progress_bar.progress(40 + int((i/len(scenes))*50))
        desc = run_gemini(s['path'], google_key)
        final_data.append({"ìˆœì„œ": s['seq'], "ì‹œê°„": f"{s['time']:.1f}", "ì„¤ëª…": desc, "íŒŒì¼ëª…": s['filename']})
    
    full_script = run_whisper(video_path, openai_key)
    progress_bar.progress(100)
    
    # ì—‘ì…€ ì €ì¥
    df = pd.DataFrame(final_data)
    excel_path = "result.xlsx"
    with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:
        df.to_excel(writer, sheet_name='ì¥ë©´', index=False)
        pd.DataFrame({"ìŠ¤í¬ë¦½íŠ¸": [full_script]}).to_excel(writer, sheet_name='ìŠ¤í¬ë¦½íŠ¸', index=False)
        
    st.balloons()
    with open(excel_path, "rb") as f:
        st.download_button("ğŸ“¥ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ", f, file_name="í—Œìˆ˜í•™ë‹¹_ì™„ì„±ë³¸.xlsx")
        
    # ê²°ê³¼ í‘œì‹œ
    cols = st.columns(3)
    for i, row in df.iterrows():
        cols[i%3].image(os.path.join(OUTPUT_DIR, row['íŒŒì¼ëª…']), caption=f"#{row['ìˆœì„œ']}")